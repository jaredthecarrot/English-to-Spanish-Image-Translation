{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jared\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:188: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"transformer\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positional_embeddi… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,845,120</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbeddi…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_encoder │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,155,456</span> │ positional_embed… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ functional_5        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">12,959,640</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">15000</span>)            │            │ transformer_enco… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positional_embeddi… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m3,845,120\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mPositionalEmbeddi…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_encoder │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m3,155,456\u001b[0m │ positional_embed… │\n",
       "│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ functional_5        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │ \u001b[38;5;34m12,959,640\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │ \u001b[38;5;34m15000\u001b[0m)            │            │ transformer_enco… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,960,216</span> (76.14 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,960,216\u001b[0m (76.14 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,960,216</span> (76.14 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,960,216\u001b[0m (76.14 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m716s\u001b[0m 637ms/step - accuracy: 0.7080 - loss: 2.2706 - val_accuracy: 0.7854 - val_loss: 1.3484\n"
     ]
    }
   ],
   "source": [
    "# Main File Until Otherwise\n",
    "# Importing Necessary Libraries and\n",
    "# Modules from Keras and TensorFlow API\n",
    "# Alongside Python Libraries\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "import pathlib\n",
    "import random\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow.data as tf_data\n",
    "import tensorflow.strings as tf_strings\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import ops\n",
    "from keras.layers import TextVectorization\n",
    "\n",
    "file = keras.utils.get_file(\n",
    "    fname=\"spa-eng.zip\",\n",
    "    origin=\"http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\",\n",
    "    extract=True,\n",
    ")\n",
    "file = pathlib.Path(file).parent / \"spa-eng\" / \"spa.txt\"\n",
    "\n",
    "# Separate the source sequence and target sequence\n",
    "# Source = English, Target = Spanish\n",
    "\n",
    "with open(file, encoding=\"utf8\") as f:\n",
    "    lines = f.read().split(\"\\n\")[:-1]\n",
    "pairs = []\n",
    "for line in lines:\n",
    "    # Source and Target are Tab Delimited\n",
    "    eng, spa = line.split(\"\\t\")\n",
    "    # Tokenizing start and end of sequence\n",
    "    spa = \"[start] \" + spa + \" [end]\"\n",
    "    pairs.append((eng,spa))\n",
    "# Dataset should be partially tokenized, and made into a list of English\n",
    "    # and Spanish translations\n",
    "\n",
    "random.shuffle(pairs)\n",
    "# Split the pairs of sentences into training, validation, and test sets\n",
    "\n",
    "number_validation_samples = int(0.20 * len(pairs))\n",
    "number_training_samples = len(pairs) - 2 * number_validation_samples\n",
    "training = pairs[:number_training_samples]\n",
    "validation = pairs[number_training_samples: number_training_samples + number_validation_samples]\n",
    "testing = pairs[number_training_samples + number_validation_samples :]\n",
    "\n",
    "# Now we have training, validation, and testing pairs\n",
    "\n",
    "# Vectorization will be performed using TextVectorization\n",
    "# First, need to strip punctuation\n",
    "\n",
    "strip_chars = string.punctuation + \"¿\"\n",
    "strip_chars = strip_chars.replace(\"[\", \"\")\n",
    "strip_chars = strip_chars.replace(\"]\", \"\")\n",
    "\n",
    "vocab = 15000\n",
    "seq_len = 20\n",
    "batsize = 64\n",
    "def standard(i_string):\n",
    "    lc = tf_strings.lower(i_string)\n",
    "    return tf_strings.regex_replace(lc, \"[%s]\" % re.escape(strip_chars), \"\")\n",
    "\n",
    "eng_vec = TextVectorization(\n",
    "    max_tokens = 15000,\n",
    "    output_mode = \"int\",\n",
    "    output_sequence_length = 20,\n",
    ")\n",
    "\n",
    "spa_vec = TextVectorization(\n",
    "    max_tokens = 15000,\n",
    "    output_mode = \"int\",\n",
    "    output_sequence_length = 21, # Additional integer for the Spanish punc\n",
    "    standardize = standard,\n",
    ")\n",
    "\n",
    "training_eng_text = [pair[0] for pair in training]\n",
    "training_spa_text = [pair[1] for pair in training]\n",
    "eng_vec.adapt(training_eng_text)\n",
    "spa_vec.adapt(training_spa_text)\n",
    "\n",
    "# After each set is vectorized, formatting is necessary\n",
    "\n",
    "def format(eng, spa):\n",
    "    eng = eng_vec(eng)\n",
    "    spa = spa_vec(spa)\n",
    "    return (\n",
    "        {\n",
    "            \"encoder_inputs\": eng,\n",
    "            \"decoder_inputs\":spa[:, :-1],\n",
    "        },\n",
    "        spa[:, 1:],\n",
    "    )\n",
    "\n",
    "def create(pairs):\n",
    "    eng_text, spa_text = zip(*pairs)\n",
    "    eng_text = list(eng_text)\n",
    "    spa_text = list(spa_text)\n",
    "    dset = tf_data.Dataset.from_tensor_slices((eng_text, spa_text))\n",
    "    dset = dset.batch(64)\n",
    "    dset = dset.map(format)\n",
    "    return dset.cache().shuffle(2048).prefetch(16)\n",
    "\n",
    "training_dset = create(training)\n",
    "validation_dset = create(validation)\n",
    "\n",
    "# Now our training and validation datasets are complete\n",
    "# Our Transformer model will have an encoder, decoder, and positional embedding\n",
    "\n",
    "import keras.ops as ops\n",
    "\n",
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embed, dense, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed = embed\n",
    "        self.dense = dense\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = layers.MultiHeadAttention(\n",
    "            num_heads = num_heads, key_dim = embed\n",
    "        )\n",
    "        self.projection = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(dense, activation = \"relu\"),\n",
    "                layers.Dense(embed),\n",
    "            ]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization()\n",
    "        self.layernorm2 = layers.LayerNormalization()\n",
    "        self.supports_masking =  True\n",
    "\n",
    "    def call(self, inputs, mask = None):\n",
    "        if mask is not None:\n",
    "            padmask = ops.cast(mask[:, None, :], dtype = \"int32\")\n",
    "        else:\n",
    "            padmask = None\n",
    "            \n",
    "        attention_output = self.attention(\n",
    "            query = inputs, value = inputs, key = inputs, attention_mask = padmask,\n",
    "        )\n",
    "        input_projection = self.layernorm1(inputs + attention_output)\n",
    "        output_projection = self.projection(input_projection)\n",
    "        return self.layernorm2(input_projection + output_projection)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                \"embed_dim\": self.embed,\n",
    "                \"dense_dim\": self.dense,\n",
    "                \"num_heads\": self.num_heads,\n",
    "            }\n",
    "            )\n",
    "        return config\n",
    "\n",
    "# Positional Embedding\n",
    "\n",
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, seq_len, vocab, embed, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.token_embeddings = layers.Embedding(\n",
    "            input_dim = vocab,\n",
    "            output_dim = embed,\n",
    "        )\n",
    "        self.position_embeddings = layers.Embedding(\n",
    "            input_dim = seq_len,\n",
    "            output_dim = embed,\n",
    "        )\n",
    "        self.seq_len = seq_len\n",
    "        self.vocab = vocab\n",
    "        self.embed = embed\n",
    "\n",
    "    def call(self, inputs):\n",
    "        len = ops.shape(inputs)[-1]\n",
    "        positions = ops.arange(0, len, 1)\n",
    "        embedtoks = self.token_embeddings(inputs)\n",
    "        embedpos = self.position_embeddings(positions)\n",
    "        return embedtoks + embedpos\n",
    "\n",
    "    def comp_mask(self, inputs, mask = None):\n",
    "        if mask is None:\n",
    "            return None\n",
    "        else:\n",
    "            return ops.not_equal(inputs, 0)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                \"seq_len\": self.seq_len,\n",
    "                \"vocab\": self.vocab,\n",
    "                \"embed\": self.embed,\n",
    "            }\n",
    "        )\n",
    "        return config\n",
    "    \n",
    "class TransformerDecoder(layers.Layer):\n",
    "    def __init__(self, embed, latent, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed = embed\n",
    "        self.latent = latent\n",
    "        self.num_heads = num_heads\n",
    "        self.attention1 = layers.MultiHeadAttention(\n",
    "            num_heads = num_heads,\n",
    "            key_dim = embed,\n",
    "        )\n",
    "        self.attention2 = layers.MultiHeadAttention(\n",
    "            num_heads = num_heads,\n",
    "            key_dim = embed\n",
    "        )\n",
    "        self.projection = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(latent, activation = \"relu\"),\n",
    "                layers.Dense(embed),\n",
    "            ]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization()\n",
    "        self.layernorm2 = layers.LayerNormalization()\n",
    "        self.layernorm3 = layers.LayerNormalization()\n",
    "        self.supp_mask = True\n",
    "\n",
    "    def call(self, inputs, encode_out, mask = None):\n",
    "        casmask = self.get_cam(inputs)\n",
    "        if mask is not None:\n",
    "            padmask = ops.cast(mask[:, None, :], dtype = \"int32\")\n",
    "            padmask = ops.minimum(padmask, casmask)\n",
    "        else:\n",
    "            padmask = None\n",
    "\n",
    "        attention_output1 = self.attention1(\n",
    "            query = inputs,\n",
    "            value = inputs,\n",
    "            key = inputs,\n",
    "            attention_mask = casmask,\n",
    "        )\n",
    "        out1 = self.layernorm1(inputs + attention_output1)\n",
    "\n",
    "        attention_output2 = self.attention2(\n",
    "            query = out1,\n",
    "            value = encode_out,\n",
    "            key = encode_out,\n",
    "            attention_mask = padmask,\n",
    "        )\n",
    "        out2 = self.layernorm2(out1 + attention_output2)\n",
    "\n",
    "        projection = self.projection(out2)\n",
    "        return self.layernorm3(out2 + projection)\n",
    "\n",
    "    def get_cam(self, inputs):\n",
    "        input_shape = ops.shape(inputs)\n",
    "        batsize, seq_len = input_shape[0], input_shape[1]\n",
    "        i = ops.arange(seq_len)[:, None]\n",
    "        j = ops.arange(seq_len)\n",
    "        mask = ops.cast(i >= j, dtype = \"int32\")\n",
    "        mask = ops.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
    "        mult = ops.concatenate(\n",
    "            [ops.expand_dims(batsize, -1), ops.convert_to_tensor([1,1])],\n",
    "            axis = 0,\n",
    "        )\n",
    "        return ops.tile(mask, mult)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                \"embed\": self.embed,\n",
    "                \"latent\": self.latent,\n",
    "                \"num_heads\": self.num_heads,\n",
    "            }\n",
    "        )\n",
    "        return config\n",
    "\n",
    "embed_dim = 256\n",
    "latent_dim = 2048\n",
    "num_heads = 8\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
    "x = PositionalEmbedding(seq_len, vocab, embed_dim)(encoder_inputs)\n",
    "encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x)\n",
    "encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
    "\n",
    "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\",name=\"decoder_inputs\")\n",
    "encoded_seq_inputs = keras.Input(shape=(None, embed_dim), name=\"decoder_state_inputs\")\n",
    "x = PositionalEmbedding(seq_len, vocab, embed_dim)(decoder_inputs)\n",
    "x = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, encoded_seq_inputs)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "decoder_outputs = layers.Dense(vocab, activation=\"softmax\")(x)\n",
    "decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n",
    "\n",
    "decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
    "transformer = keras.Model(\n",
    "    [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",
    ")\n",
    "\n",
    "transformer.summary()\n",
    "transformer.compile(\n",
    "    \"rmsprop\", loss = \"sparse_categorical_crossentropy\", metrics = [\"accuracy\"]\n",
    ")\n",
    "\n",
    "transformer.fit(training_dset, epochs = 1, validation_data = validation_dset)\n",
    "\n",
    "spa_vocab = spa_vec.get_vocabulary()\n",
    "spa_index_lookup = dict(zip(range(len(spa_vocab)), spa_vocab))\n",
    "max_decoded_sentence_length = 20\n",
    "\n",
    "\n",
    "def decode_sequence(input_sentence):\n",
    "    tokenized_input_sentence = eng_vec([input_sentence])\n",
    "    decoded_sentence = \"[start]\"\n",
    "    for i in range(max_decoded_sentence_length):\n",
    "        tokenized_target_sentence = spa_vec([decoded_sentence])[:, :-1]\n",
    "        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n",
    "\n",
    "        sampled_token_index = ops.convert_to_numpy(\n",
    "            ops.argmax(predictions[0, i, :])\n",
    "        ).item(0)\n",
    "        sampled_token = spa_index_lookup[sampled_token_index]\n",
    "        decoded_sentence += \" \" + sampled_token\n",
    "\n",
    "        if sampled_token == \"[end]\":\n",
    "            break\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 6102000965106784480\n",
      "xla_global_id: -1\n",
      "]\n",
      "Tom thought he had outsmarted everybody.\n",
      "[start] tom se dio a tom lo que tom se lo que tom [end]\n",
      "I'll go back to Boston.\n",
      "[start] te voy a boston [end]\n",
      "He is washing a car.\n",
      "[start] Él es un buen niño [end]\n",
      "Tom couldn't ask for more.\n",
      "[start] tom no se lo [UNK] [end]\n",
      "She saw him at the station.\n",
      "[start] ella le dio a la puerta con la puerta [end]\n",
      "You're smart.\n",
      "[start] estás seguro de acuerdo [end]\n",
      "I didn't dare do that.\n",
      "[start] no me dijo que lo que lo hizo [end]\n",
      "Don't you have a meeting?\n",
      "[start] no tienes un buen trabajo [end]\n",
      "Everybody loves her.\n",
      "[start] todo el mundo se se se [UNK] [end]\n",
      "Give it to me.\n",
      "[start] dame que me lo que me [UNK] [end]\n",
      "Guns don't kill people. People kill people.\n",
      "[start] la gente no se [UNK] a la puerta de la puerta [end]\n",
      "Do you know what I mean?\n",
      "[start] sabes lo que lo que me lo que me [UNK] [end]\n",
      "We heard tigers roaring in the distance.\n",
      "[start] nos [UNK] en la puerta en la puerta [end]\n",
      "I think you should think about the future.\n",
      "[start] creo que te puedo hablar con la puerta [end]\n",
      "It's ours.\n",
      "[start] es lo que está [UNK] [end]\n",
      "She was ready to help him with cleaning the house.\n",
      "[start] ella estaba seguro de que le dio a la puerta con ella [end]\n",
      "I wasn't expecting visitors.\n",
      "[start] yo estaba buscando [end]\n",
      "Tom doesn't know what Mary does for a living.\n",
      "[start] tom no sabe lo que mary se lo que mary se lo que tom [end]\n",
      "I second the motion.\n",
      "[start] me pregunto la puerta [end]\n",
      "I've got nothing to say to him.\n",
      "[start] me he visto nada que le gusta [end]\n",
      "They say that she was born in Germany.\n",
      "[start] ellos se lo que ella estaba en la puerta [end]\n",
      "Put it on my desk.\n",
      "[start] lo [UNK] de mi madre [end]\n",
      "You can only use it once.\n",
      "[start] puedes haber sido más de que se lo que se lo [UNK] [end]\n",
      "He's not sure he wants to do this.\n",
      "[start] Él no es lo que le gusta hablar [end]\n",
      "Our country's climate is temperate.\n",
      "[start] nuestro niño es más de que la puerta [end]\n",
      "Are you rich?\n",
      "[start] estás seguro de acuerdo [end]\n",
      "He got lost in the park.\n",
      "[start] Él se ha estado en la puerta [end]\n",
      "I work in a tourist agency.\n",
      "[start] me he estado en un buen trabajo [end]\n",
      "Hawks are birds of prey.\n",
      "[start] el mundo están de los niños [end]\n",
      "The bad harvest caused massive food shortages.\n",
      "[start] el niño se [UNK] de la puerta de la puerta [end]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "conda install -c conda-forge cudatoolkit=11.2 cudnn=8.1.0\n",
    "# Anything above 2.10 is not supported on the GPU on Windows Native\n",
    "python -m pip install \"tensorflow<2.11\"\n",
    "# Verify the installation:\n",
    "python -c \"import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))\"\n",
    "\n",
    "test_eng_texts = [pair[0] for pair in testing]\n",
    "for _ in range(30):\n",
    "    input_sentence = random.choice(test_eng_texts)\n",
    "    translated = decode_sequence(input_sentence)\n",
    "    print(input_sentence)\n",
    "    print(translated)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
